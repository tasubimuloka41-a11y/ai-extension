========================================
ГДЕ НАЙТИ URL ТВОЕГО API
========================================

ЭТО АДРЕС, ГДЕ ЗАПУЩЕНА ТВОЯ МОДЕЛЬ GEMMA 3 12B
-------------------------------------------------

ВАРИАНТ 1: ЕСЛИ ИСПОЛЬЗУЕШЬ OLLAMA
------------------------------------
1. Запусти Ollama:
   ollama serve

2. URL будет:
   http://localhost:11434

3. Введи в настройках расширения:
   http://localhost:11434


ВАРИАНТ 2: ЕСЛИ ИСПОЛЬЗУЕШЬ LM STUDIO
--------------------------------------
1. Запусти LM Studio
2. Включи Local Server
3. URL обычно:
   http://localhost:1234

4. Введи в настройках расширения:
   http://localhost:1234


ВАРИАНТ 3: ЕСЛИ ИСПОЛЬЗУЕШЬ СВОЙ СЕРВЕР
----------------------------------------
1. Запусти свой API сервер
2. Посмотри на каком порту он работает
3. URL будет:
   http://localhost:ПОРТ

   Например:
   http://localhost:8000
   http://localhost:5000
   http://localhost:3000


ВАРИАНТ 4: ЕСЛИ НЕ ЗНАЕШЬ
--------------------------
1. Открой командную строку (cmd)
2. Выполни:
   netstat -ano | findstr LISTENING

3. Посмотри какие порты заняты
4. Попробуй стандартные:
   - http://localhost:11434 (Ollama)
   - http://localhost:1234 (LM Studio)
   - http://localhost:8000 (обычный API)


КАК ПРОВЕРИТЬ РАБОТАЕТ ЛИ API
-------------------------------
1. Открой браузер
2. Вставь URL (например: http://localhost:11434)
3. Если видишь ответ - работает!
4. Если ошибка - сервер не запущен


ЧТО ДЕЛАТЬ ЕСЛИ НЕ РАБОТАЕТ
----------------------------
1. Убедись что модель запущена
2. Проверь что порт правильный
3. Попробуй другой порт
4. Перезапусти сервер модели

========================================

